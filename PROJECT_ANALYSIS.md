# Token-Efficient OpenClaw: Implementation Analysis
**Created:** 2026-02-12  
**Analyzed by:** Opus  
**To be implemented by:** Sonnet  
**Status:** Analysis Complete - Ready for Implementation

---

## Executive Summary

This project implements comprehensive token cost reduction for OpenClaw while maintaining reasoning quality, safety, and operational correctness. The core strategy is **intelligent model routing** (cheap-first with escalation), **bounded context**, and **zero-token heartbeats**.

**Expected Impact:**
- **60-80% token reduction** during routine operations
- **90-100% heartbeat cost elimination** (currently ~50% of usage)
- **40-60% context reduction** (selective loading vs unlimited)
- **Preserved quality** for complex reasoning tasks (10k bundle = substantial context)
- **Auditable cost tracking** with daily rollups

---

## Current Architecture Understanding

### Existing OpenClaw Structure

**Configuration File:** `/home/node/.openclaw/openclaw.json`
```json
{
  "agents": {
    "defaults": {
      "model": {
        "primary": "anthropic/claude-sonnet-4-5"
      },
      "models": {
        "anthropic/claude-opus-4-5": { "alias": "opus" },
        "openai/gpt-4o": { "alias": "gpt-4o" }
      },
      "contextTokens": 24000,
      "maxConcurrent": 4
    }
  }
}
```

**Key Files:**
- `/home/node/.openclaw/openclaw.json` - main config
- `/home/node/.openclaw/agents/` - agent-specific configs
- `/home/node/.openclaw/workspace/` - workspace files
- `/home/node/.openclaw/telegram/` - Telegram connector state
- `/home/node/.openclaw/cron/` - cron jobs

**Model Selection:** Currently hardcoded to single model per session
**Context Management:** Unlimited context injection from workspace + Telegram history
**Heartbeat:** Unknown current implementation (needs investigation)

---

## Implementation Roadmap

### Phase 1: Configuration Schema Extensions âš¡ CRITICAL

**File:** `/home/node/.openclaw/openclaw.json`

Add three new top-level configuration blocks:

#### 1.1 Model Policy (Model Routing)
```json
{
  "modelPolicy": {
    "defaults": {
      "cheap": "openai/gpt-4o",
      "mid": "anthropic/claude-sonnet-4-5",
      "high": "anthropic/claude-opus-4-5"
    },
    "routes": {
      "heartbeat": "none",
      "file_ops": "cheap",
      "extract": "cheap",
      "summarize": "cheap",
      "write": "mid",
      "code": "mid",
      "strategy": "high"
    },
    "escalation": ["cheap", "mid", "high"],
    "maxAttempts": 3,
    "escalationTriggers": {
      "validation_failure": true,
      "tool_error_repeated": true,
      "uncertainty_signal": true
    }
  }
}
```

**Implementation Notes:**
- Add TypeScript interfaces in `/app/dist/plugin-sdk/gateway/protocol/schema/agents-models-skills.d.ts`
- Validate on gateway startup
- Provide defaults if not specified

#### 1.2 Context Policy (Bounded Context)
```json
{
  "contextPolicy": {
    "baseline": {
      "maxTokens": 2000,
      "files": ["context/safety.md", "context/routing.md"]
    },
    "bundles": {
      "coding": {
        "maxTokens": 10000,
        "files": ["context/coding.md", "TOOLS.md", "AGENTS.md"]
      },
      "ops": {
        "maxTokens": 8000,
        "files": ["context/ops.md", "AGENTS.md"]
      },
      "writing": {
        "maxTokens": 6000,
        "files": ["context/writing.md", "SOUL.md"]
      }
    },
    "routes": {
      "heartbeat": [],
      "file_ops": ["baseline"],
      "extract": ["baseline"],
      "summarize": ["baseline"],
      "write": ["baseline", "writing"],
      "code": ["baseline", "coding"],
      "strategy": ["baseline", "coding"]
    },
    "hardCapBehavior": "summarize_then_attach",
    "maxHistoryMessages": 50,
    "totalBudget": 28000
  }
}
```

**Implementation Notes:**
- Enforce maxTokens hard cap BEFORE building prompt
- If exceeded â†’ summarize bundle using GPT-4o
- Never auto-attach full workspace or unlimited Telegram history
- Total budget (28k) leaves room for user message + response within Sonnet's 30k window
- Bundle sizes calibrated for quality operation:
  - 10k coding = AGENTS.md + TOOLS.md + coding guidelines + examples
  - 8k ops = AGENTS.md + ops context + tool references
  - 6k writing = SOUL.md + writing guidelines + tone examples
- 50 messages â‰ˆ 10k tokens â‰ˆ 15-20 min of conversation continuity

#### 1.3 Budget Guardrails
```json
{
  "budgets": {
    "maxTokensPerTask": 120000,
    "maxCostPerTaskUSD": 5.0,
    "maxDailyCostUSD": 25.0,
    "onExceed": "pause_and_report",
    "alertThresholds": {
      "taskCostUSD": 2.0,
      "dailyCostUSD": 20.0
    }
  }
}
```

**Implementation Notes:**
- Check BEFORE making LLM call
- Log all rejections to audit log
- Send Telegram notification on exceed

---

### Phase 2: Task Classification System

**File:** Create `/home/node/.openclaw/workspace/context/task-classifier.js`

```javascript
/**
 * Classifies incoming requests into task types for model routing
 * 
 * @param {string} userMessage - The user's message
 * @param {object} context - Session context
 * @returns {string} taskType - One of: heartbeat, file_ops, extract, summarize, write, code, strategy
 */
function classifyTask(userMessage, context) {
  // Classification logic
  // Priority order (first match wins):
  
  // 1. Heartbeat (should be caught upstream, but fallback)
  if (context.trigger === 'heartbeat') return 'heartbeat';
  
  // 2. File operations
  if (/^(read|write|edit|ls|cat|find|grep)/i.test(userMessage)) return 'file_ops';
  
  // 3. Extract/Parse operations
  if (/(extract|parse|get|fetch|scrape|pull)/i.test(userMessage)) return 'extract';
  
  // 4. Summarize operations
  if (/(summarize|summary|tldr|brief|overview)/i.test(userMessage)) return 'summarize';
  
  // 5. Code/Programming
  if (/(code|function|debug|implement|refactor|script|program)/i.test(userMessage)) return 'code';
  
  // 6. Strategy/Planning/Deep reasoning
  if (/(analyze|design|architecture|strategy|plan|should|evaluate|decide|recommend)/i.test(userMessage)) return 'strategy';
  
  // 7. Default to write (mid tier)
  return 'write';
}

module.exports = { classifyTask };
```

**Integration Point:**
- Hook into agent turn handler BEFORE model selection
- Store taskType in session metadata
- Log taskType in audit log

---

### Phase 3: Model Router with Escalation

**File:** Create `/home/node/.openclaw/workspace/lib/model-router.js`

```javascript
/**
 * Selects the appropriate model based on task type and escalation state
 * 
 * @param {string} taskType - Task classification
 * @param {number} attempt - Current attempt number (0-indexed)
 * @param {object} lastError - Previous error if any
 * @param {object} config - modelPolicy from openclaw.json
 * @returns {string|null} modelId - Selected model or null for heartbeat
 */
function selectModel(taskType, attempt, lastError, config) {
  const { defaults, routes, escalation, maxAttempts } = config;
  
  // Heartbeat never gets a model
  if (taskType === 'heartbeat' || routes[taskType] === 'none') {
    return null;
  }
  
  // Get base tier from routes
  const tierName = routes[taskType] || 'mid'; // default to mid
  
  // Check if we should escalate
  let effectiveTier = tierName;
  if (attempt > 0 && shouldEscalate(lastError, config)) {
    const currentIndex = escalation.indexOf(tierName);
    const targetIndex = Math.min(currentIndex + attempt, escalation.length - 1);
    effectiveTier = escalation[targetIndex];
  }
  
  // Respect maxAttempts
  if (attempt >= maxAttempts) {
    throw new Error(`Max attempts (${maxAttempts}) exceeded for task type: ${taskType}`);
  }
  
  // Map tier to model
  return defaults[effectiveTier];
}

/**
 * Determines if escalation is warranted based on error
 */
function shouldEscalate(lastError, config) {
  if (!lastError) return false;
  
  const triggers = config.escalationTriggers;
  
  // Validation failure
  if (triggers.validation_failure && lastError.type === 'validation') {
    return true;
  }
  
  // Repeated tool errors
  if (triggers.tool_error_repeated && lastError.type === 'tool_error' && lastError.count >= 2) {
    return true;
  }
  
  // Explicit uncertainty ("I'm not sure", "I don't know")
  if (triggers.uncertainty_signal && lastError.type === 'uncertainty') {
    return true;
  }
  
  return false;
}

module.exports = { selectModel, shouldEscalate };
```

**Integration Points:**
- Replace hardcoded model selection in agent handler
- Track attempt count in session state
- Log escalations to audit log

---

### Phase 4: Context Manager with Bundles

**File:** Create `/home/node/.openclaw/workspace/lib/context-manager.js`

```javascript
const fs = require('fs');
const path = require('path');

/**
 * Builds bounded context payload based on task type and policy
 * 
 * @param {string} taskType - Classified task type
 * @param {object} config - contextPolicy from openclaw.json
 * @param {string} workspaceRoot - Workspace root path
 * @returns {object} { files: [...], totalTokens, truncated }
 */
async function buildContext(taskType, config, workspaceRoot) {
  const { baseline, bundles, routes, hardCapBehavior, maxHistoryMessages, totalBudget } = config;
  
  // Get bundle names for this task type
  const bundleNames = routes[taskType] || [];
  
  // Start with empty context
  let contextFiles = [];
  let totalTokens = 0;
  
  // Add bundles in order
  for (const bundleName of bundleNames) {
    const bundle = bundleName === 'baseline' ? baseline : bundles[bundleName];
    if (!bundle) continue;
    
    for (const filePath of bundle.files) {
      const fullPath = path.join(workspaceRoot, filePath);
      
      // Read file
      if (!fs.existsSync(fullPath)) {
        console.warn(`Context file not found: ${fullPath}`);
        continue;
      }
      
      let content = fs.readFileSync(fullPath, 'utf8');
      const fileTokens = estimateTokens(content);
      
      // Check hard cap
      if (totalTokens + fileTokens > bundle.maxTokens) {
        if (hardCapBehavior === 'summarize_then_attach') {
          // Summarize this file using GPT-4o
          content = await summarizeFile(content, bundle.maxTokens - totalTokens);
        } else {
          // Skip or truncate
          console.warn(`Skipping ${filePath} - would exceed bundle limit`);
          continue;
        }
      }
      
      contextFiles.push({
        path: filePath,
        content,
        tokens: fileTokens
      });
      
      totalTokens += fileTokens;
    }
  }
  
  return {
    files: contextFiles,
    totalTokens,
    truncated: totalTokens >= baseline.maxTokens
  };
}

/**
 * Rough token estimation (4 chars = 1 token)
 */
function estimateTokens(text) {
  return Math.ceil(text.length / 4);
}

/**
 * Summarize file content using GPT-4o
 */
async function summarizeFile(content, maxTokens) {
  // Call GPT-4o with summarization prompt
  // Return condensed version
  // Implementation depends on OpenClaw SDK
  return content; // Placeholder
}

module.exports = { buildContext, estimateTokens };
```

**Context Files to Create:**
```
/home/node/.openclaw/workspace/context/
â”œâ”€â”€ safety.md          # Safety constraints, basic rules (~800 tokens)
â”œâ”€â”€ routing.md         # Task classification hints (~1200 tokens)
â”œâ”€â”€ coding.md          # Coding guidelines, best practices (~3000 tokens)
â”œâ”€â”€ ops.md             # Operations/DevOps context (~3000 tokens)
â””â”€â”€ writing.md         # Writing style, tone guidelines (~2000 tokens)
```

**Note:** AGENTS.md, SOUL.md, TOOLS.md, MEMORY.md are NOT in context/ because they already exist in workspace root. Bundles reference them by path.

**Integration Points:**
- Replace current context injection in agent handler
- Log context size in audit log
- Never attach SOUL.md, AGENTS.md, MEMORY.md unless explicitly in bundle

---

### Phase 5: Telegram Session Control ðŸš¨ CRITICAL

**Issue:** Telegram connectors fetch entire chat history by default, causing massive context bloat.

**File:** Modify `/home/node/.openclaw/telegram/` (or wherever Telegram plugin lives)

#### 5.1 Truncate History
```javascript
// In Telegram message handler
function getTelegramHistory(chatId, config) {
  const maxMessages = config.contextPolicy?.maxHistoryMessages || 50;
  
  // Fetch only last N messages
  const messages = fetchTelegramMessages(chatId, { limit: maxMessages });
  
  return messages;
}
```

**Rationale:** 50 messages â‰ˆ 10k tokens â‰ˆ 15-20 min of conversation, providing good continuity without bloat.

#### 5.2 Implement `/new session` Command
```javascript
// In Telegram command handler
async function handleNewSession(chatId, config) {
  // 1. Summarize recent messages (using GPT-4o)
  const recentMessages = fetchTelegramMessages(chatId, { limit: 50 });
  const summary = await summarizeConversation(recentMessages);
  
  // 2. Write summary to memory
  const date = new Date().toISOString().split('T')[0];
  const memoryPath = `/home/node/.openclaw/workspace/memory/${date}.md`;
  fs.appendFileSync(memoryPath, `\n\n## Session Reset (${new Date().toISOString()})\n${summary}\n`);
  
  // 3. Clear Telegram session context
  clearTelegramContext(chatId);
  
  // 4. Confirm to user
  return "âœ… Session reset. Recent conversation summarized to memory. Starting fresh.";
}
```

**Integration Points:**
- Add `/new` command to Telegram plugin
- Hook into session manager
- Test with long-running Telegram conversations

---

### Phase 6: Zero-Token Heartbeat Implementation

**File:** Modify `/home/node/.openclaw/cron/` (or heartbeat scheduler)

#### Current Problem
If heartbeat currently invokes LLM, it's burning tokens on every interval (e.g., every 30 min = 48 calls/day).

#### Solution: Logic-Only Heartbeat
```javascript
/**
 * Heartbeat handler - MUST NEVER call LLM
 */
async function handleHeartbeat(config) {
  // Read HEARTBEAT.md
  const heartbeatPath = '/home/node/.openclaw/workspace/HEARTBEAT.md';
  const instructions = fs.readFileSync(heartbeatPath, 'utf8');
  
  // If empty or only comments, skip
  if (isEmptyOrComments(instructions)) {
    return { action: 'skip', model: null, externalTokens: 0 };
  }
  
  // Parse instructions as structured data (NOT free text)
  const tasks = parseHeartbeatTasks(instructions);
  
  // Execute checks locally (no LLM)
  const alerts = [];
  for (const task of tasks) {
    const result = await executeCheck(task); // Local logic only
    if (result.alert) {
      alerts.push(result.message);
    }
  }
  
  // If alerts exist, send Telegram notification (direct API call, no LLM)
  if (alerts.length > 0) {
    await sendTelegramAlert(alerts.join('\n'));
  }
  
  return { action: 'complete', model: null, externalTokens: 0 };
}

/**
 * Parse HEARTBEAT.md as structured task list
 * Format: JSON or YAML, NOT natural language
 */
function parseHeartbeatTasks(content) {
  // Expected format:
  // ```json
  // {
  //   "checks": [
  //     { "type": "file_exists", "path": "/tmp/test.txt" },
  //     { "type": "git_status", "repo": "~/projects/repo" }
  //   ]
  // }
  // ```
  return JSON.parse(content);
}
```

**HEARTBEAT.md Format (Update AGENTS.md guidance):**
```markdown
# HEARTBEAT.md - Structured Task List

Do NOT use natural language. Use JSON only.

```json
{
  "checks": [
    {
      "type": "file_exists",
      "path": "/home/node/.openclaw/workspace/memory/heartbeat-state.json",
      "alert_if": "missing"
    },
    {
      "type": "interval_check",
      "name": "email",
      "interval_seconds": 14400,
      "action": "send_notification",
      "message": "Check email inbox"
    }
  ]
}
```
```

**Integration Points:**
- Modify cron scheduler to call logic-only heartbeat
- NEVER pass heartbeat context to LLM
- Log heartbeat executions with `externalTokens: 0`

---

### Phase 7: Token Auditing System

**File:** Create `/home/node/.openclaw/workspace/lib/token-auditor.js`

```javascript
const fs = require('fs');
const path = require('path');

class TokenAuditor {
  constructor(logPath = '/home/node/.openclaw/audit_log.jsonl') {
    this.logPath = logPath;
  }
  
  /**
   * Log a single LLM call
   */
  log(entry) {
    const record = {
      timestamp: new Date().toISOString(),
      trigger: entry.trigger, // 'user' | 'tool' | 'retry' | 'heartbeat'
      taskType: entry.taskType,
      model: entry.model,
      promptTokens: entry.promptTokens,
      completionTokens: entry.completionTokens,
      totalTokens: entry.promptTokens + entry.completionTokens,
      estimatedCostUSD: this.calculateCost(entry.model, entry.promptTokens, entry.completionTokens),
      durationMs: entry.durationMs,
      cacheHit: entry.cacheHit || false,
      payloadBreakdown: entry.payloadBreakdown || {},
      escalation: entry.escalation || false,
      attempt: entry.attempt || 0
    };
    
    fs.appendFileSync(this.logPath, JSON.stringify(record) + '\n');
  }
  
  /**
   * Calculate cost based on model pricing
   */
  calculateCost(model, promptTokens, completionTokens) {
    const pricing = {
      'openai/gpt-4o': { prompt: 0.0025 / 1000, completion: 0.01 / 1000 },
      'anthropic/claude-sonnet-4-5': { prompt: 0.003 / 1000, completion: 0.015 / 1000 },
      'anthropic/claude-opus-4-5': { prompt: 0.015 / 1000, completion: 0.075 / 1000 }
    };
    
    const prices = pricing[model] || { prompt: 0, completion: 0 };
    return (promptTokens * prices.prompt) + (completionTokens * prices.completion);
  }
  
  /**
   * Generate daily rollup report
   */
  async generateDailyReport(date = new Date()) {
    const dateStr = date.toISOString().split('T')[0];
    const reportPath = `/home/node/.openclaw/daily_audit.md`;
    
    const logs = this.readLogsForDate(dateStr);
    
    const report = this.buildReport(logs, dateStr);
    
    fs.writeFileSync(reportPath, report);
    
    return reportPath;
  }
  
  /**
   * Read logs for a specific date
   */
  readLogsForDate(dateStr) {
    const allLogs = fs.readFileSync(this.logPath, 'utf8')
      .split('\n')
      .filter(line => line.trim())
      .map(line => JSON.parse(line));
    
    return allLogs.filter(log => log.timestamp.startsWith(dateStr));
  }
  
  /**
   * Build markdown report
   */
  buildReport(logs, date) {
    const totalTokens = logs.reduce((sum, log) => sum + log.totalTokens, 0);
    const totalCost = logs.reduce((sum, log) => sum + log.estimatedCostUSD, 0);
    
    const modelUsage = {};
    logs.forEach(log => {
      if (!modelUsage[log.model]) {
        modelUsage[log.model] = { count: 0, tokens: 0, cost: 0 };
      }
      modelUsage[log.model].count++;
      modelUsage[log.model].tokens += log.totalTokens;
      modelUsage[log.model].cost += log.estimatedCostUSD;
    });
    
    const heartbeatTokens = logs.filter(log => log.trigger === 'heartbeat')
      .reduce((sum, log) => sum + log.totalTokens, 0);
    
    const top10 = logs
      .sort((a, b) => b.estimatedCostUSD - a.estimatedCostUSD)
      .slice(0, 10);
    
    return `# Token Audit Report - ${date}

## Summary
- **Total Tokens:** ${totalTokens.toLocaleString()}
- **Total Cost:** $${totalCost.toFixed(4)}
- **Total Calls:** ${logs.length}

## Model Usage
${Object.entries(modelUsage).map(([model, stats]) => `
### ${model}
- Calls: ${stats.count}
- Tokens: ${stats.tokens.toLocaleString()}
- Cost: $${stats.cost.toFixed(4)}
`).join('\n')}

## Heartbeat Tokens
**Heartbeat external tokens:** ${heartbeatTokens} (MUST be 0)
${heartbeatTokens > 0 ? 'âš ï¸ WARNING: Heartbeat is burning tokens!' : 'âœ… Heartbeat is token-free'}

## Top 10 Expensive Calls
${top10.map((log, i) => `
${i + 1}. **${log.taskType}** (${log.model})
   - Tokens: ${log.totalTokens.toLocaleString()}
   - Cost: $${log.estimatedCostUSD.toFixed(4)}
   - Time: ${log.timestamp}
`).join('\n')}
`;
  }
}

module.exports = { TokenAuditor };
```

**Integration Points:**
- Wrap every LLM call with auditor.log()
- Schedule daily report generation (cron job)
- Send daily report to Telegram

---

### Phase 8: Budget Guardrails Enforcement

**File:** Create `/home/node/.openclaw/workspace/lib/budget-guard.js`

```javascript
const fs = require('fs');

class BudgetGuard {
  constructor(config, auditor) {
    this.config = config;
    this.auditor = auditor;
    this.todaySpend = 0;
    this.loadTodaySpend();
  }
  
  /**
   * Check if task can proceed within budget
   */
  async checkBudget(taskType, model, estimatedTokens) {
    const { maxTokensPerTask, maxCostPerTaskUSD, maxDailyCostUSD } = this.config;
    
    // Estimate cost
    const estimatedCost = this.auditor.calculateCost(model, estimatedTokens, estimatedTokens * 0.3);
    
    // Check per-task limits
    if (estimatedTokens > maxTokensPerTask) {
      return {
        allowed: false,
        reason: `Task would exceed maxTokensPerTask (${maxTokensPerTask})`
      };
    }
    
    if (estimatedCost > maxCostPerTaskUSD) {
      return {
        allowed: false,
        reason: `Task would exceed maxCostPerTaskUSD ($${maxCostPerTaskUSD})`
      };
    }
    
    // Check daily limit
    if (this.todaySpend + estimatedCost > maxDailyCostUSD) {
      return {
        allowed: false,
        reason: `Would exceed maxDailyCostUSD ($${maxDailyCostUSD}). Current: $${this.todaySpend.toFixed(2)}`
      };
    }
    
    return { allowed: true };
  }
  
  /**
   * Record actual spend
   */
  recordSpend(cost) {
    this.todaySpend += cost;
    this.saveTodaySpend();
  }
  
  /**
   * Load today's spend from audit log
   */
  loadTodaySpend() {
    const today = new Date().toISOString().split('T')[0];
    const logs = this.auditor.readLogsForDate(today);
    this.todaySpend = logs.reduce((sum, log) => sum + log.estimatedCostUSD, 0);
  }
  
  /**
   * Save spend state
   */
  saveTodaySpend() {
    const statePath = '/home/node/.openclaw/budget-state.json';
    fs.writeFileSync(statePath, JSON.stringify({
      date: new Date().toISOString().split('T')[0],
      spend: this.todaySpend
    }));
  }
}

module.exports = { BudgetGuard };
```

**Integration Points:**
- Check budget BEFORE every LLM call
- If rejected, log to audit log with `blocked: true`
- Send Telegram notification on budget exceed

---

### Phase 9: System Prompt Updates

**File:** Modify system prompt injection (likely in agent runtime)

**Add to Core System Prompt:**
```
## Token Efficiency (Critical)

You must minimize token usage while preserving correctness:

1. **Prefer shorter outputs** - Be concise by default. Expand only if explicitly requested.
2. **Use structured data** - JSON/YAML over prose when possible.
3. **Never request full history** - Work with provided context only.
4. **No redundant confirmations** - Skip "Great question!" and "I'd be happy to help!"
5. **If a cheaper model can do it, don't escalate** - Use your full capability only when needed.

Token cost is a first-class optimization metric.
```

**Add to Planner/Router Prompt (if exists):**
```
## Model Selection Strategy

- Default to the cheapest capable model
- Escalate only on clear failure conditions:
  - Validation failure
  - Repeated tool errors (2+)
  - Explicit uncertainty
- Never escalate preemptively
```

**Add to Writing Prompts:**
```
Be concise by default. Expand only if explicitly requested.
```

---

### Phase 10: Testing & Validation Strategy

#### 10.1 Unit Tests
**File:** Create `/home/node/.openclaw/workspace/tests/token-economy/`

```
tests/token-economy/
â”œâ”€â”€ task-classifier.test.js
â”œâ”€â”€ model-router.test.js
â”œâ”€â”€ context-manager.test.js
â”œâ”€â”€ budget-guard.test.js
â””â”€â”€ integration.test.js
```

**Key Test Cases:**
- Task classification accuracy (100 samples)
- Model routing correctness (all task types Ã— escalation levels)
- Context size enforcement (exceed limits, verify truncation/summarization)
- Budget guardrails (hit limits, verify rejection)
- Heartbeat zero-token guarantee (mock 100 heartbeats, assert 0 external calls)

#### 10.2 Integration Tests
**Scenarios:**
1. **Simple file operation** â†’ GPT-4o, <1000 tokens
2. **Code generation** â†’ Sonnet, <10k tokens
3. **Complex strategy** â†’ Opus, <50k tokens
4. **Heartbeat (empty HEARTBEAT.md)** â†’ 0 tokens
5. **Telegram long history** â†’ Truncated to 50 messages (~10k tokens, ~15-20 min context)
6. **Budget exceeded** â†’ Blocked, notification sent
7. **Escalation path** â†’ cheap â†’ mid â†’ high

#### 10.3 Before/After Metrics
**Collect for 7 days before implementation:**
- Total tokens per day
- Cost per day
- Tokens per task type (estimate manually)
- Heartbeat token usage

**Collect for 7 days after implementation:**
- Same metrics
- Calculate % reduction
- Document in project README

---

### Phase 11: Migration Plan

#### 11.1 Backup Current Config
```bash
cp /home/node/.openclaw/openclaw.json /home/node/.openclaw/openclaw.json.pre-token-economy
```

#### 11.2 Staged Rollout
1. **Week 1:** Implement config schema + auditing (passive logging only)
2. **Week 2:** Enable model routing + context policy (with overrides available)
3. **Week 3:** Enable budget guardrails (with high limits)
4. **Week 4:** Tighten limits based on observed patterns

#### 11.3 Rollback Plan
```bash
# If anything breaks
cp /home/node/.openclaw/openclaw.json.pre-token-economy /home/node/.openclaw/openclaw.json
docker compose restart openclaw-gateway
```

#### 11.4 Feature Flags
Add to config:
```json
{
  "tokenEconomy": {
    "enabled": true,
    "features": {
      "modelRouting": true,
      "contextPolicy": true,
      "budgetGuardrails": true,
      "heartbeatLogicOnly": true
    }
  }
}
```

Allow disabling individual features without full rollback.

---

### Phase 12: Documentation Requirements

#### 12.1 Project Documentation
**File:** `/home/node/.openclaw/workspace/projects/token-economy/README.md`

Must include:
- Goals & motivation
- Architecture overview
- Configuration guide
- Before/after metrics
- Troubleshooting guide
- Known limitations

#### 12.2 RAG Knowledge Base
**Files to create for RAG ingestion:**
```
/home/node/.openclaw/workspace/knowledge/
â”œâ”€â”€ token-economy-overview.md
â”œâ”€â”€ model-routing-rules.md
â”œâ”€â”€ context-policy-rules.md
â”œâ”€â”€ heartbeat-invariants.md
â””â”€â”€ budget-guardrails.md
```

**Tags:** `openclaw`, `token-optimization`, `model-routing`, `cost-reduction`

#### 12.3 GitHub Repository
**Repository:** https://github.com/pfaria32/open_claw_token_economy.git

**File:** `/home/node/.openclaw/workspace/projects/token-economy/TOKEN_EFFICIENCY.md`

```markdown
# Token Efficiency Guarantees

This OpenClaw instance implements strict token economy:

## Guarantees
1. âœ… Heartbeat uses **0 external tokens**
2. âœ… Simple tasks use **GPT-4o (cheap tier)**
3. âœ… Opus reserved for **complex reasoning only**
4. âœ… Context capped at **10k tokens max per bundle** (sufficient for complex tasks)
5. âœ… Daily spend capped at **$25 USD**
6. âœ… All LLM usage is **auditable** (JSONL log)

## How to Avoid Cost Regressions
- Never modify `modelPolicy.routes` without testing
- Keep `HEARTBEAT.md` as structured JSON (not natural language)
- Monitor `daily_audit.md` for anomalies
- Use `/model status` to check current routing

## Cost Tracking
```bash
# View today's audit report
cat ~/.openclaw/daily_audit.md

# Check current budget
grep "todaySpend" ~/.openclaw/budget-state.json
```

## Repository
This project is version-controlled at:
https://github.com/pfaria32/open_claw_token_economy
```

#### 12.4 Update AGENTS.md
**File:** `/home/node/.openclaw/workspace/AGENTS.md`

Add section:
```markdown
## ðŸ’° Token Economy

**This instance runs under strict token budget.**

### Model Tiers
- **Cheap (GPT-4o):** File ops, extract, summarize
- **Mid (Sonnet):** Writing, code, default
- **High (Opus):** Strategy, complex reasoning only

### Rules
1. **Heartbeat = Logic Only** - Never call LLM in heartbeat
2. **Context is Bounded** - Max 10k tokens per bundle (quality + economy balance)
3. **History is Truncated** - Telegram limited to 50 messages (~15-20 min context)
4. **Budget is Enforced** - $25/day hard cap

### HEARTBEAT.md Format
Use structured JSON ONLY:
```json
{
  "checks": [
    { "type": "interval_check", "name": "email", "interval_seconds": 14400 }
  ]
}
```

Never use natural language in HEARTBEAT.md.
```

---

## Implementation Checklist

### Phase 1: Config Schema âœ…
- [ ] Add `modelPolicy` to openclaw.json
- [ ] Add `contextPolicy` to openclaw.json
- [ ] Add `budgets` to openclaw.json
- [ ] Add `tokenEconomy.enabled` feature flag
- [ ] Validate config on gateway startup

### Phase 2: Task Classification âœ…
- [ ] Create `context/task-classifier.js`
- [ ] Integrate into agent turn handler
- [ ] Add unit tests
- [ ] Log taskType in audit log

### Phase 3: Model Router âœ…
- [ ] Create `lib/model-router.js`
- [ ] Implement `selectModel()` with escalation
- [ ] Replace hardcoded model selection
- [ ] Add unit tests
- [ ] Log escalations

### Phase 4: Context Manager âœ…
- [ ] Create `lib/context-manager.js`
- [ ] Create context files (safety.md, routing.md, etc.)
- [ ] Implement bundle loading with hard caps
- [ ] Implement summarization fallback (GPT-4o)
- [ ] Replace current context injection
- [ ] Add unit tests

### Phase 5: Telegram Session Control âœ…
- [ ] Modify Telegram plugin to truncate history (50 messages â‰ˆ 10k tokens)
- [ ] Implement `/new session` command
- [ ] Test with long-running conversations
- [ ] Document in user guide

### Phase 6: Zero-Token Heartbeat âœ…
- [ ] Modify heartbeat handler to be logic-only
- [ ] Update HEARTBEAT.md format (JSON only)
- [ ] Test with 100 heartbeats, assert 0 external tokens
- [ ] Update AGENTS.md guidance

### Phase 7: Token Auditing âœ…
- [ ] Create `lib/token-auditor.js`
- [ ] Wrap all LLM calls with auditor.log()
- [ ] Implement daily report generation
- [ ] Schedule daily report via cron
- [ ] Send report to Telegram

### Phase 8: Budget Guardrails âœ…
- [ ] Create `lib/budget-guard.js`
- [ ] Check budget before every LLM call
- [ ] Block calls that would exceed limits
- [ ] Send Telegram notifications on exceed
- [ ] Add unit tests

### Phase 9: System Prompt Updates âœ…
- [ ] Add efficiency constraints to core prompt
- [ ] Add model selection strategy to planner prompt
- [ ] Add conciseness guidance to writing prompts
- [ ] Test with sample conversations

### Phase 10: Testing âœ…
- [ ] Write unit tests for all modules
- [ ] Write integration tests (7 scenarios)
- [ ] Collect before metrics (7 days)
- [ ] Collect after metrics (7 days)
- [ ] Document % reduction

### Phase 11: Migration âœ…
- [ ] Backup current config
- [ ] Staged rollout (4 weeks)
- [ ] Add rollback plan
- [ ] Implement feature flags
- [ ] Monitor for issues

### Phase 12: Documentation âœ…
- [ ] Create project README
- [ ] Create RAG knowledge base files
- [ ] Create TOKEN_EFFICIENCY.md for GitHub
- [ ] Update AGENTS.md
- [ ] Initialize git repository in project directory
- [ ] Commit all changes (code, scripts, docs)
- [ ] Push to https://github.com/pfaria32/open_claw_token_economy.git
- [ ] Tag with release version (v1.0.0)

---

## Critical Success Factors

### Must-Haves
1. **Heartbeat = 0 tokens** (ABSOLUTE requirement)
2. **Auditable cost tracking** (JSONL log + daily reports)
3. **Sonnet remains default** (mid tier)
4. **GPT-4o handles cheap tasks** (file ops, extract, summarize)
5. **Opus is rare** (strategy only, with escalation)

### Nice-to-Haves
- Automatic context summarization (vs truncation)
- Per-user budget tracking
- Real-time cost dashboard
- Slack/Discord integration for alerts

### Known Limitations
- Model quality may vary by task (GPT-4o vs Sonnet trade-offs)
- Context summarization may lose nuance
- Escalation may not catch all cases needing Opus
- Budget caps may block legitimate high-value tasks

### Risk Mitigation
- Feature flags allow selective disabling
- Rollback plan ready
- Staged rollout reduces blast radius
- Audit log provides forensics

---

## Open Questions for Sonnet

1. **Where is the agent turn handler in OpenClaw?**
   - Need exact file path to integrate task classifier + model router
   - Likely in `/app/dist/agent-*.js` but need confirmation

2. **Where is Telegram plugin code?**
   - Need to modify history fetching + add `/new` command
   - Likely in `/app/dist/plugin-sdk/` or `/app/dist/` (telegram-related)

3. **Where is heartbeat scheduler?**
   - Need to modify to be logic-only
   - May be in `/home/node/.openclaw/cron/` or gateway runtime

4. **How does current context injection work?**
   - Need to replace with bounded context manager
   - Likely in agent prompt builder

5. **Is there existing audit/logging infrastructure?**
   - Can we extend it or need to build from scratch?

6. **What's the correct way to hook into LLM calls?**
   - Need intercept point for auditing + budget checks
   - Middleware pattern? Wrapper class?

---

## Cost Reduction Estimates

### Current State (Estimated)
- **Heartbeat:** ~50% of tokens (48 calls/day Ã— 2k context = 96k tokens/day)
- **File ops:** 20% (should be GPT-4o)
- **Writing:** 20% (Sonnet appropriate)
- **Strategy:** 10% (Opus appropriate)

**Daily cost estimate:** ~$3-5/day

### Target State (After Implementation)
- **Heartbeat:** 0 tokens (0% of usage)
- **File ops:** GPT-4o (-70% cost per call)
- **Writing:** Sonnet (unchanged)
- **Strategy:** Opus (unchanged)
- **Context:** -50% due to bounded bundles

**Daily cost estimate:** ~$0.80-1.50/day

**Projected savings:** 60-80% reduction

---

## Timeline Estimate

- **Phase 1-3 (Config + Routing):** 2-3 days
- **Phase 4-5 (Context + Telegram):** 2-3 days
- **Phase 6-8 (Heartbeat + Auditing + Budget):** 2-3 days
- **Phase 9-10 (Prompts + Testing):** 2-3 days
- **Phase 11-12 (Migration + Docs):** 1-2 days

**Total:** 9-14 days (conservative)

With focused effort: **5-7 days**

---

## Next Steps for Sonnet

1. **Investigate OpenClaw codebase** (answer Open Questions above)
2. **Create project directory** (`mkdir -p projects/token-economy`)
3. **Start with Phase 1** (config schema changes)
4. **Implement incrementally** (one phase at a time, test each)
5. **Keep this document updated** (mark completed phases)
6. **Document discoveries** (add to project README)

**Important:** Do not implement all at once. Go phase by phase, test thoroughly, then move to next phase.

---

## Authorization from User

Pedro explicitly authorized:
> "I want to implement much stricter token economy... implementation and coding will be done afterward by sonnet"

This analysis provides the complete blueprint. Sonnet has full authority to proceed with implementation.

---

**End of Analysis Document**

*This document will be version-controlled in the project repository and maintained as the canonical implementation guide.*
